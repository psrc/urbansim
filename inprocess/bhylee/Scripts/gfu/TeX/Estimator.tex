\documentclass[12pt]{article}

\usepackage[sumlimits]{amsmath}
\usepackage{txfonts}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{verbatim}
%
\voffset=-1in
\hoffset=-1in
%
% Set for US Letter
\textheight=9.0in
\textwidth=6.5in
% need to also set dvips config and pdflatex config to US letter
%
%
\topmargin=0.5in
\oddsidemargin=1in
\evensidemargin=1in
%
\frenchspacing
%
%
% xxxxxxxxx  nnnnnnnnnnnnnnnn
%       nnnnnnnnnnnnnnnnnnnnn
\newenvironment{longitem}
	{\begin{list}{$\bullet$}
				{\labelwidth=2.6cm\leftmargin=2.9cm\labelsep=0.3cm
				\itemsep=0cm}}
	{\end{list}}
%
% Vector command (sets vectors in bold roman, not italic)
\newcommand{\vc}[1]{\boldsymbol{\mathrm{#1}}}
%
\itemsep=0in
%
%
%
\begin{document}

\begin{titlepage}
\begin{center}
\mbox{}
\vspace{2in}

\Huge The UrbanSim Estimator\\
\vspace{0.5in}
\LARGE Guðmundur F. Úlfarsson\\
\vspace{0.2in}
\large Evans School of Public Affairs \\
University of Washington\\
\vfill
\large\today
\thispagestyle{empty}
\end{center}
\end{titlepage}

\normalsize

\pagenumbering{roman}

\tableofcontents
\clearpage
\listoftables
\clearpage

\setcounter{page}{1}
\pagenumbering{arabic}

%
%
%
\section{Introduction}

The UrbanSim Estimator (the estimator) is used to automatically estimate the
coefficients of estimable model components
within UrbanSim. This avoids the need for outside model estimation
software. Currently we estimate
coefficients for linear regression models (land price),
logistic regression models (residential land share),
and logit models
(household location, employment location, real-estate developer).

The estimator has the following major components:
%
\begin{enumerate}\itemsep=0cm
	\item Parameter Reader,
	\item Estimation Controller,
	\item Function Generator,
	\item Coefficient Estimator.
\end{enumerate}
%


%
%
%
\section{Parameter Reader}

Reads user input specifications from an XML file (see \ref{ap:sample-xml}). 
The user must specify:
%
\begin{itemize}\itemsep=0cm
	\item Model type:
	%
	\begin{itemize}
		\item Linear Regression
		\item Multinomial Logit (MNL)
	\end{itemize}

	\item Name and location of database table containing input data;
	\item Formats (one or more) for result output: 
	%
	\begin{itemize}
		\item UrbanSim model specification and coefficients tables
		\item Documentation file
	\end{itemize}

	\item Model-specific data; explained in the following sections.
\end{itemize}

%
%
\subsection{Linear Regression Model Input Parameters}

The linear regression model needs these additional input parameters:
%
\begin{itemize}
	\item Model function (see specification in Section~\ref{se:lreg-spec})
	\item Estimation method (exactly one):
		\begin{itemize}
			\item \emph{Ordinary Least Squares} (OLS)
			\item \ldots
		\end{itemize}
\end{itemize}
% 
Currently, we only implement OLS.

%
\subsubsection{Linear Regression Model Function Specification}
\label{se:lreg-spec}

The linear regression model needs exactly one model function to be
specified by the user. The coefficients of this function will be
estimated.
The input reading of this function shouldn't depend on white-space
(including tab and newline) since the function could be long and the
reader may need to format it for easy viewing in the XML file.

The linear regression model function is on the form:
%
\begin{equation}
	d = \alpha + \beta_1*x_1 + \cdots + \beta_{K^*}* x_K
\end{equation}
%
where 
%
\begin{itemize}\itemsep=0cm
	\item[$d$] is the name of the dependent variable that
	UrbanSim will predict; 
	\item[$x_k$] with $k=1,\ldots ,K$, 
		are the names of $K$ different explanatory variables; 
		these names must match the names of variables that exist
		in the input data table;
	\item[$\alpha$] is the name of the estimable intercept term 
		(it is a coefficient on a constant variable which is always equal to 
		1 and therefore omitted);
	\item[$\beta_{k^*}$] with $k^*=1,\ldots ,K^*$,
		are the names of $K^*\leq K$ estimable coefficients. 
\end{itemize}

If $K^*<K$ it
indicates that the coefficients on the explanatory variables are not all
different, and that the coefficients on two or more explanatory
variables have been restricted to be equal, i.e. the same coefficient
belongs to two or more explanatory variables.

Example:
%
\begin{eqnarray}
	\mathit{ln\_land\_price} & =
	& \mathit{intercept\_term}
		+ \mathit{residential\_units\_coeff}
			* \mathit{residential\_units}\nonumber \\
	& & + \mathit{non\_residential\_sqft\_coeff}*\mathit{non\_residential\_sqft}
\end{eqnarray}
%
The estimable coefficients are: 
%
\begin{quote}
\emph{intercept\_term},
\emph{residential\_units\_coeff}, and
\emph{non\_residential\_sqft\_coeff}.
\end{quote}
%
The variable names are:
%
\begin{quote}
\emph{ln\_land\_price}, \emph{residential\_units},
\emph{non\_residential\_sqft}, 
\end{quote}
%
and they must match names in the input data table so they can be located.


%
%
\subsection{Multinomial Logit Model Input Parameters}

The multinomial logit model (MNL) is used in UrbanSim as a 
\emph{discrete choice model}. 
A \emph{decision maker} has $C$ mutually exclusive \emph{alternatives}, 
where $C\geq 2$, and the logit
model predicts the probability that a decision maker chooses any one of
these alternatives. The alternatives grouped together are called the
\emph{choice set} of the decision maker, and the size of the choice set
is $C$.

MNL needs these additional input parameters:
%
\begin{itemize}
	\item Model functions (see specification in Section~\ref{se:mnl-spec})
	\item Estimation method (exactly one):
	\begin{itemize}
		\item \emph{Maximum Likelihood with Newton Optimization}
		\begin{itemize}
			\item \emph{Function tolerance}: maximum absolute change in 
				likelihood function across iterations;
			\item \emph{Coefficient tolerance}: maximum absolute change in 
				coefficients across iterations;
			\item \emph{Gradient tolerance}: maximum absolute gradient;
			\item \emph{Step size};
		\end{itemize}
		\item \ldots
%		\item \emph{Markov-Chain Monte Carlo} (for future expansion);
	\end{itemize}
	\item \emph{Maximum number of iterations};
	\item Name of \emph{choice indicator} in input data, so the column 
		containing the choice indicator can be located;
	\item Name of \emph{alternative ID} variable in input data, so the column 
		containing the alternative IDs can be located;
	\item Names and column location of all \emph{explanatory variables} in 
		input data;
	\item Optional \emph{starting values} for coefficients.
\end{itemize}
%
Currently, we only implement the maximum likelihood with Newton optimization.
The tolerances are used for maximum likelihood estimation and
will be used to stop iterations when our values drop
below the tolerances. 

%
\subsubsection{Multinomial Logit Model Function Specification}
\label{se:mnl-spec}

MNL requires exactly one model function to be specified per
alternative in the model (if we have four alternatives we need four
model functions). The model functions are called \emph{utility
functions}. There are always at least two utility functions in a logit
model, one can be equal to zero.
The input reading of these functions shouldn't depend on white-space
(including tab and newline) since the functions can be long and the
reader may need to format them for easy viewing in the XML file.

We need two different ways of writing utility functions; these ways can be
mixed and matched. The ways are the \emph{single-equation} form and the 
\emph{multi-equation} form. 

The single-equation logit utility function form is:
%
\begin{equation}
	\mathrm{U}(c) = \alpha + \beta_1*x_1 + \cdots + \beta_{K^*}*x_K
\end{equation}
%
where
%
\begin{itemize}\itemsep=0cm
	\item[$c$] is the name of the alternative (also called alternative ID) and
	must match the alternative IDs used in the input data to identify the
	alternatives; 

	\item[$x_k$] with $k=1,\ldots ,K$, 
	are the names of $K$ different explanatory variables,
	these names must match the names of variables in the input data; 

	\item[$\alpha$] is the name of the estimable intercept term 
	(it is a coefficient on a constant
	variable which is always equal to 1 for this alternative, $c$,
	and therefore omitted); 

	\item[$\beta_{k^*}$] with $k^*=1,\ldots ,K^*$,
	are the names of $K^*\leq K$ estimable coefficients. 
\end{itemize}
%
If $\alpha$ is
omitted it means it has been restricted to be equal to zero.

Note, if the same coefficient name appears in a function for another
alternative $c^*\neq c$, it means the coefficient is restricted to be the
same in both equations and must be treated as one single coefficient in
the estimation. We later show an example of how that can be done.

Special case (but quite common):
%
\begin{equation}
	\mathrm{U}(c) = 0
\end{equation}
%
means all coefficients are restricted to zero in the utility function
for alternative $c$ and the utility is fixed at zero in the
estimation.

The multi-equation logit utility function form is:
%
\begin{equation}
\mathrm{U}(c_1,\ldots ,c_C) = <\alpha_1,\ldots ,\alpha_C> 
+ <\beta_{11},\ldots ,\beta_{C1}>*x_1 + \cdots  
+ <\beta_{1K},\ldots ,\beta_{CK}>*x_K
\end{equation}
%
where 
%
\begin{longitem}
	\item[$c_1,\ldots ,c_C$] is a list of $C$ names of alternatives 
		(alternative IDs) and must match with $C$ different alternative 
		IDs used in the input data to identify the alternatives; 

	\item[$C$] is the number of utility equations represented by this form;

	\item[$x_k$] with $k=1,\ldots ,K$,
		are the names of $K$ different explanatory variables;

	\item[$<\alpha_1,\ldots ,\alpha_C>$] is a list of $C$ names of
		the estimable intercept terms in the $C$ different utility functions; 

	\item[$<\beta_{1k},\ldots ,\beta_{Ck}>$] with $k=1,\ldots ,K$,
		is a list of $C$ (not necessarily different) coefficient names 
		that represent the coefficients on the $k$-th variable in 
		the utility functions for the alternatives identified by 
		$c_1,\ldots ,c_C$.
		If the coefficient names are not different 
		it means they are restricted to be the same
		and should be treated as a single coefficient in the estimation. 
		One or more of these
		coefficients can be a real number. In particular, $\beta_{ck}=0$,
		indicates the $k$-th coefficient in alternative $c$
		has been restricted to that real number (in this case zero),
		and shouldn't be estimated in the estimation process since estimation 
		would change the coefficient from its restricted value.
\end{longitem}
%
%

Let's now explore an example of a logit model with $C=3$ alternatives,
called: \emph{no\_build}, \emph{build\_house}, \emph{build\_apts}. Let us
assume we have $K=4$ explanatory variables: \emph{land\_price},
\emph{accessibility}, \emph{density}, \emph{cost}. We will write sample
utility functions in both single-equation and multi-equation formats.

Single-equation format:
\begin{eqnarray*}
\mathrm{U}(\mathit{no\_build}) & = & 0 \\
\mathrm{U}(\mathit{build\_house}) & = 
&	\mathit{house\_constant} + \mathit{cost\_coeff}*\mathit{cost}
	+ \mathit{price\_house}*\mathit{land\_price} \\
& & + \mathit{accessdens}*\mathit{accessibility}
	+ \mathit{accessdens}*\mathit{density} \\
\mathrm{U}(\mathit{build\_apts}) & = 
&	\mathit{apt\_constant} + \mathit{cost\_coeff}*\mathit{cost}
	+ \mathit{price\_apt}*\mathit{land\_price} \\
& &	+ 6*\mathit{accessibility} + \mathit{accessdens}*\mathit{density} \\
\end{eqnarray*}

Multi-equation format:
\begin{align*}
\mathrm{U}(\mathit{no\_build},&\mathit{build\_house},\mathit{build\_apts}) 
= <0,\mathit{house\_constant},\mathit{apt\_constant}> \\
&+ <0,\mathit{cost\_coeff},\mathit{cost\_coeff}>*\mathit{cost} 
+ <0,\mathit{price\_house},\mathit{price\_apt}>*\mathit{land\_price} \\
&+ <0,\mathit{accessdens},6>*\mathit{accessibility} 
+ <0,\mathit{accessdens},\mathit{accessdens}>*\mathit{density}
\end{align*}

Note first that the utility function for the no build alternative is a
constant zero function. The other two functions both have constants
(called alternative-specific constants). There are a number of
restrictions across coefficients. The coefficient on the \emph{cost}
variables is restricted to be equal in both the build house and build
apartments alternatives. The coefficient on \emph{accessibility} and
\emph{density} in the build house alternative and on \emph{density} in
the build apartments alternative have all been restricted to be one
coefficient. The coefficient on \emph{accessibility} in the build
apartments alternative has been restricted to the real number six.
The coefficients on \emph{land price} are unrestricted, i.e. separate in the
two equations. 

\subsubsection{Potential representation of the logit model
specification}

Create two vectors and a matrix. 

\begin{enumerate}
\item The first vector is a vector for all
estimable coefficients, their initial values are the starting values given
by the user or by default all zeros.

\item The second vector is a vector for all restricted coefficients.

\item The matrix has one row per utility function and one column per variable
in the whole model. A zero value in location $(i,j)$ indicates that
variable $j$ is not used in equation $i$. A positive value $\geq 1$ in
$(i,j)$ indicates the number of the coefficient on variable $j$
in equation $i$ in the estimable coefficient vector. 
A negative value $\leq 1$ in
$(i,j)$ indicates the number of the coefficient on variable $j$
in equation $i$ in the restricted coefficient vector.
\end{enumerate}

This means that the example MNL model discussed in 
section~\ref{se:mnl-spec} will be represented as:
\begin{eqnarray}
C = & []\\
R = & []\\
M = & \left[
	\begin{array}{ccc}
	\end{array}
	\right].
\end{eqnarray}
%
%
%
\section{Estimation Controller}

The estimation controller:
%
\begin{itemize}\itemsep=0cm
	\item Accepts user input from the parameter reader
	(see Appendix~\ref{ap:sample-xml}); 
	\item Examines the inputs for general consistency 
	(see Section~\ref{se:general-ctrl});
	\item Calls model-specific estimation control 
	(see Sections~\ref{se:lreg-ctrl}--\ref{se:mnl-ctrl});
	\item Publishes output in all user specified output formats
	(see Appendix~\ref{ap:output}).
\end{itemize}

%
%
\subsection{Examining Input Parameters for General Consistency}
\label{se:general-ctrl}

The model type must be one of:
\begin{itemize}
	\item Linear Regression,
	\item Multinomial Logit (MNL).
\end{itemize}
%
There must be:
\begin{itemize}
	\item A valid file name for input data file, the file can be opened OR
		the user states the data should be found in a specific database table;
	\item A description of input data, either by 
		the user stating therer is a header row in the data file
		or if not, a list of names of variables and their column number.
\end{itemize}
%
There must be listed one or more output formats
(see samples in Appendix~\ref{ap:output}): 
\begin{itemize}
	\item UrbanSim coefficient XML file,
	\item Documentation file,
	\item Database table of coefficients.
\end{itemize}
%


%
%
\subsection{Linear Regression Estimation Control}
\label{se:lreg-ctrl}

For linear regression models the estimation method type must be
%one of
\begin{itemize}
	\item Ordinary Least Squares (OLS).
\end{itemize}
%
The process of estimation control for linear regression is as follows:
\begin{enumerate}
	\item Verify that the user-specified linear regression model
	function string is of the proper syntax, do clean-up to simplify
	parsing.
	\item Pass the cleaned linear regression model function string,
	along with the estimation method type, to the coefficient estimator.
	\item Take output from coefficient estimator.
%	\item Perform further analysis that may involve changing 
%		the models and running the estimator repeatedly.
	\item Return output from model-specific control to general control.
\end{enumerate}

%
%
\subsection{Multinomial Logit Estimation Control}
\label{se:mnl-ctrl}

For logit models the estimation method type must be
%one of
\begin{itemize}
	\item Maximum Likelihood with Newton Optimization.
%	\item Markov-Chain Monte Carlo
\end{itemize}
%
For logit models the default values for model-specific input parameters 
are as follows:
\begin{itemize}
	\item Function tolerance: maximum absolute change in likelihood 
		function across iterations: Default $10^{-5}$. Constraint: $>0$.
	\item Coefficient tolerance: maximum absolute change in coefficients 
		across iterations: Default $10^{-5}$. Constraint: $>0$.
	\item Gradient tolerance: maximum absolute gradient: Default $10^{-5}$.
		Constraint: $>0$.
	\item Maximum number of iterations: Default 100. Constraint: $\geq 0$.
	\item Newton optimization step size: Default 1.  Constraint: $>0$.
	\item Coefficient starting values: Default 0 for all coefficients.
\end{itemize}
%
Input parameters with default values are optionally specified by the
user but they are required by the model.

The process of estimation control for MNL is as follows:
\begin{enumerate}
	\item Verify that the user-specified MNL utility function strings
	are of the proper syntax, do clean-up to simplify parsing.
	\item Pass the cleaned utility function strings to the function
	generator.
	\item Run the function generator to generate the multinomial
		logit log-likelihood function.
	\item Pass the logit log-likelihood function along with the
		estimation method type and model-specific input parameters to the 
		coefficient estimator.
	\item Take output from coefficient estimator.
%	\item Perform further analysis that may involve changing 
%		the models and running the estimator repeatedly.
	\item Return output from model-specific control to general control.
\end{enumerate}

%
Special case: When the maximum number of iterations for a logit model is
0 run the coefficient estimator as usual, accept its output as the final
estimates, and proceed normally to output the model results for the
starting values.

In the future: The controller can explore the coefficient estimator output
and use decision rules to change the restrictions on coefficients 
from what is specified by the user in an attempt to improve the model.
This behavior must be controlled by the user through the input
parameters. Currently we will not specify this control and model improvement
feature but just run the model once with the user specification.


%
%
%
\section{Function Generator}

The function generator is not used for single-equation regression models
(such as the ones we now use) since their coefficients can be estimated
directly. The function generator is needed for the logit models because
they are made up of two or more utility functions which must be used to
generate one likelihood function. The likelihood function is then used
by the coefficient estimator to arrive at coefficient estimates.

The estimation
controller knows which model types need the function generator.
The function generator generates a function (the estimation
function) which can give its values, its gradient, and its Hessian, evaluated
at a certain point. The point is input as a multi-dimensional array of real
numbers. This point is a vector of coefficient values,
which match the unique coefficients in the model
functions specified by the user.
The function is linked to the input data where it retrieves variable values.


%
%
\subsection{Generating the Logit Log-Likelihood Function}

The logit model is comprised of two or more utility functions. To
estimate the coefficients of those functions we employ the method of
maximum likelihood. To proceed with that method we must generate the
logit likelihood function. Likelihood functions are proportional to
the probability of a probability model generating the observed data 
given a set of coefficient values. 
By maximizing the likelihood we find the coefficients that
are, in this sense, most likely to have resulted in the observed data.

Because the values can become extremely
large or small we have taken the natural logarithm of the likelihood. 
The function generator is therefore used to form the 
\emph{logit log-likelihood function}. 
The estimation controller
will pass this function to the function optimizer, which will maximize
the log-likelihood as a function of the coefficients.

The example of logit utility functions given in 
Section~\ref{se:mnl-spec} will be used
here to explain how the logit log-likelihood function is generated.
The log-likelihood becomes a function of the unique estimable
coefficients in the whole system. In our example, those will be:
%
\begin{enumerate}\itemsep=0cm
	\item house\_constant,
	\item cost\_coeff,
	\item price\_house,
	\item accessdens,
	\item apt\_constant,
	\item price\_apt.
\end{enumerate}
%
We therefore have, $M=6$, six coefficients in the total system of,
$C=3$, three utility
functions, with a total of, $K=4$, four explanatory variables. We need
to count the alternative-specific constant as one more variable
(alternative-specific variable), yielding a total of, $J=K+1=5$,
five variables in the logit model.

It is simplest to view all variables as entering all
equations, but in some equations the coefficient has been restricted to
zero. This is, in a sense, what the multi-equation format explicitly
shows.

One way to form a log-likelihood function that accounts for the restrictions
across coefficients on different variables and in different alternatives,
is to create a mapping between the vector
of the $M=6$ unique estimable coefficients 
(this is the input vector to the logit log-likelihood function),
%
\begin{equation}
	\vc{\beta} = [\mathit{house\_constant}, \mathit{cost\_coeff},
		\mathit{price\_house}, \mathit{accessdens}, 
		\mathit{apt\_constant}, \mathit{price\_apt}],
\end{equation}
%
and the full matrix, $\vc{B}$, of all possible coefficients:
%
\begin{equation}
	\vc{B} = \begin{array}{l|ccccc}
		\mathrm{c:Choice}\ |\hfill j: & 1:\mathrm{Constant}
			& 2:\mathrm{land\_price} 
			& 3:\mathrm{accessibility} 
			& 4:\mathrm{density} & 5:\mathrm{cost} \\ \hline
		1:\mathrm{no\_build} & 0 & 0 & 0 & 0 & 0 \\
		2:\mathrm{build\_house} & \beta_1 & \beta_3 & \beta_4 & \beta_4
			& \beta_2 \\
		3:\mathrm{build\_apts} & \beta_5 & \beta_6 & 6 & \beta_4 & \beta_2
	\end{array}
	\protect\label{eq:bck-matrix}
\end{equation}
%
The element of $\vc{B}$ for alternative $c$ and variable $j$ 
(out of the full set of $J$ variables) is denoted
by $B(c,j)$. For example, $B(2,3)$ is the coefficient on the variable
\emph{accessibility} in the utility function for the \emph{build\_house}
alternative. In our example, $B(2,3)=\beta_4$.
Note, $\beta_m$, indicates here the $m$-th element in the vector
of $M$ unique estimable coefficients, $\vc{\beta}$.

To recap, we have $J=5$ coefficients in each of the $C=3$ equations (although
some of those are restricted) yielding a total of $C\cdot J = 15$ 
maximum possible coefficients, 
but we have $M=6$ unique estimable coefficients.

Then the logit log-likelihood function becomes:
%
\begin{equation}
L(\vc{\beta}) = \sum_{n=1}^{N}\sum_{c=1}^{C} \delta_{nc} \left(
	\sum_{j=1}^{J} B(c,j)x_{ncj} 
		- \ln\left[\sum_{c'=1}^{C} 
				\exp\left(\sum_{j'=1}^{J}B(c',j')x_{nc'j'}\right)
			\right]
	\right),
\end{equation}
%
where
%
\begin{itemize}
	\item[$C$] is the number of alternatives. For now assumed to be the same
	for all decision makers.

	\item[$N$] is the number of decision makers. If all decision makers have
	the same number of alternatives ($C$) then the number of data rows in the
	input data file should equal $N\cdot C$.

	\item[$J$] is the number of all possible variables in a single
	equation, after we have included all variables in all equations.

	\item[$\vc{\beta}$] is the vector of $M$ unique estimable 
	coefficients taken as input.

	\item[$\vc{B}$] with elements $B(c,j)$, 
	represents the mapping from the large set of all possible
	$C\cdot J$ coefficients to the $M$ unique estimable coefficients, 
	$\vc{\beta}$.
	
	\item[$\delta_{nc}$] is the \emph{choice indicator} for decision 
	maker $n$ and alternative $c$. It is 1 if $n$ chose $c$, zero otherwise.

	\item[$x_{ncj}$] is the value of the $j$-th input data variable for
	decision maker $n$ and alternative $c$. 
	This is the element in row $(n-1)C+c+q$ and column $j+r$ in the input data,
	where $q$ is the number of header rows in the data file and 
	$r$ is the number of 'extra' columns to the left of the variables, i.e.
	non-variables and identifiers. Note, this is true if $J=K$ but if
	$J=K+1$, because of alternative-specific constants, then the column
	is $j-1+r$.
\end{itemize}

To be able to calculate this, we need:
%
\begin{itemize}
	\item The number of alternatives, $C$.  
	This is found from the number of utility
	functions.

	\item The number of decision makers, $N$.
	This is found from the number of data rows 
	(i.e. rows minus header rows) 
	in the input data file divided by $C$.

	\item The location of all
	explanatory variables must be known and input (means knowing $r$ if the
	data is organized with all extra columns first and explanatory variables
	later.

	\item The location of the choice indicator, $\delta_{nc}$, in the input
	data file must be known.
\end{itemize}

In addition to the logit log-likelihood function values given by
$L(\vc{\beta})$ we can supply analytical first- and second-derivatives of the
function. This facilitates optimization. It is also possible to
numerically differentiate the function during optimization.
In the first implementation of the estimator we will use numerical
differentiation (see, for example, Numerical Recipes in C, \cite{press:92}).

The logit log-likelihood first-derivative, the \emph{gradient},
is as follows, a vector of $M$
elements, the size of $\vc{\beta}$, i.e. it has as many elements as the
vector of unique estimable coefficients ($M=6$ in our example),
%
\begin{equation}
	\vc{g} = \vc{\nabla} L(\vc{\beta}) = \left[
	\begin{array}{c}
		\frac{\partial L(\vc{\beta})}{\partial\beta_1} \\
		...\\
		\frac{\partial L(\vc{\beta})}{\partial\beta_M}
	\end{array}
	\right].
\end{equation}
%
The logit log-likelihood second-derivative, the \emph{Hessian},
is an $M \times M$ matrix
as follows:
%
\begin{equation}
	\vc{H} = \vc{\nabla}^2 L(\vc{\beta}) = \left[
	\begin{array}{ccc}
		\frac{\partial^2 L(\vc{\beta})}{\partial\beta_1^2} & \cdots 
			& \frac{\partial^2 L(\vc{\beta})}{\partial\beta_1\partial\beta_M} \\
		... & ... & ... \\
		\frac{\partial^2 L(\vc{\beta})}{\partial\beta_M\partial\beta_1}
			& ... & \frac{\partial^2 L(\vc{\beta})}{\partial\beta_M^2}
	\end{array}
	\right].
\end{equation}

The logit log-likelihood function must accept as input a vector,
$\vc{\beta}$, of size $M$, 
and must allow output of the scalar value of the log-likelihood
function, the gradient vector of the log-likelihood function, and the
Hessian matrix of the log-likelihood function, all evaluated at
$\vc{\beta}$, i.e., $L(\vc{\beta})$, $\vc{g}(\vc{\beta})$, and
$\vc{H}(\vc{\beta})$.

This means the method of calculating the gradient and Hessian is
invisible to the user of the function, and we can use either numerical
differentiation (which we will do at the start) or analytical
derivatives (which we won't do for now).


%
%
%
\subsection{Coefficient Estimator}

The coefficient estimator estimates coefficients for the requested model
type. 
The coefficient estimator uses the estimation function, if needed, along with
knowledge about model type, estimation method, and the
the number of coefficients being estimated, to estimate the
coefficients and return them.

We proceed differently for the model types and estimation method types.

	\begin{itemize}
		\item Linear Regression\\
			Available estimation methods:
			\begin{itemize}
				\item Ordinary Least Squares (OLS)
			\end{itemize}
		\item Multinomial Logit (MNL)\\
			Available estimation methods:
			\begin{itemize}
				\item Maximum Likelihood with Newton Optimization
%				\item Markov-Chain Monte Carlo (for future expansion);
			\end{itemize}
	\end{itemize}


%
%
\subsection{Linear Regression Estimation---Ordinary Least Squares}

The regression model estimation is relatively simple when there are no
restrictions across coefficients, i.e. there is an equal number of
coefficients as there are variables ($K^*=K$).

To proceed with the estimation form the $N \times J$ matrix $\vc{X}$, 
the data matrix, where $N$
is the number of observations (i.e. rows in the input data file, and the rows
in the matrix), and
$J$ is the number of coefficients in the regression model function (i.e.
columns in the matrix). 
If there is an intercept term in the model then $J=K^*+1$, otherwise
$J=K^*$. In the case when there is an intercept, 
we must create one additional column in $\vc{X}$, which we
place as the first column counting from left, and this column contains
only the number 1 in all rows.

To handle a restriction across coefficients, let us study an example. In the
equation:
%
\begin{equation}
	d = \alpha + \beta_1*x_1 + \beta_2*x_2 + \beta_2*x_3,
\end{equation}
%
we have restricted the coefficients on $x_2$ and $x_3$ to be the same,
$\beta_2$. Here $K=3$, $K^*=2$, and $J=K^*+1=3$. 
Note that this is equivalent to:
%
\begin{equation}
	d = \alpha + \beta_1*x_1 + \beta_2*(x_2 + x_3).
\end{equation}
%
We therefore define, for each restriction, a restricted variable. In this
example it would be one variable:
%
\begin{equation}
	x_2^* = x_2 + x_3.
\end{equation}

The matrix $\vc{X}$ is formed from column vectors: the constant 1 column vector 
if there is an intercept in the model, and all explanatory variables or
restricted variables where appropriate. 
%
To continue the example, in this case $\vc{X}$
will comprise the column vectors:
%
\begin{equation}
	\vc{X} = [\vc{1},\vc{x}_1,\vc{x}_2^*],
\end{equation}
%
where $\vc{1}$ denotes an $N \times 1$ column vector where all elements are
the number one. 
The variables $\vc{x}_k$ are $N \times 1$ column vectors since the variables
have a value for every observation (row) in the input data file.

We next calculate a coefficient vector, which is a $J \times 1$ column
vector of the estimates of all coefficients in the model.
In our example it will have the form:
%
\begin{equation}
	\hat{\vc{\beta}}' = [\hat{\alpha},\hat{\beta}_1,\hat{\beta}_2],
\end{equation}
%
where the prime symbol on the vector, $\vc{\beta}'$, 
indicates the vector has been transposed,
i.e. a column vector written as a row vector. We do this here to save space.

The formula for the coefficient estimate is:
%
\begin{equation}
	\hat{\vc{\beta}} = (\vc{X}'\vc{X})^{-1}\vc{X}'\vc{d},
\end{equation}
%
where $\vc{X}$ is the data matrix, $\vc{X}'$ is the transposed data matrix, the
negative one power indicates the inversion of the matrix that results
from the multiplication $(\vc{X}'\vc{X})$, $\vc{d}$ is the regression model 
dependent variable, which is an $N \times 1$ vector since we have one value for
each row in the data. Referring to our example,
the vector $\hat{\vc{\beta}}$ would contain our 
estimates for the intercept coefficient 
and the two coefficients on the explanatory variables.

The calculation of the inverse matrix $(\vc{X}'\vc{X})$ 
is where this estimation
can suffer some problems. If the matrix $\vc{X}$ is singular or near-singular
then it is not invertible. It is therefore important to use an inversion
routine that is able to detect this error and exit gracefully with a
message regarding singularity. It would be beneficial
to detect which variables cause the singularity, i.e. which column
vectors in $\vc{X}$ are linearly dependent (or closely linearly dependent) on
each other. Until such a thing is implemented, exit gracefully.

In addition to the coefficient estimates we need estimates of the
standard error of the coefficient estimate and the t-statistic. 
We first calculate the residual of the regression:
%
\begin{equation}
	\hat{\vc{e}} = \vc{d} - \vc{X}\hat{\vc{\beta}}.
\end{equation}
%
Then the standard error of the regression is defined as
%
\begin{equation}
	\vc{s}^2 = \hat{\vc{e}}'\hat{\vc{e}}.
\end{equation}
%
Now we can calculate the $J \times J$ variance-covariance matrix of the
coefficient estimates:
%
\begin{equation}
	\vc{V}(\hat{\vc{\beta}}) = \frac{1}{N-J}\vc{s}^2(\vc{X}'\vc{X})^{-1}.
\end{equation}
%
The $i,j$-th element of $\vc{V}(\hat{\vc{\beta}})$ is now denoted by
$V(\hat{\beta}_i,\hat{\beta}_j)$.
The t-statistic is calculated as
%
\begin{equation}
	t(\hat{\beta}_k) =  \frac{\hat{\beta}_k}
							{\sqrt{V(\hat{\beta}_k,\hat{\beta}_k)}}.
\end{equation}

The estimated coefficients must be output, and now it is key to
recognize the restricted coefficients since we must output the
appropriate coefficient on the actual separate explanatory variables.
Continuing our example the output must contain the information
shown in
Table~\ref{ta:lreg-est}. The horizontal lines are for readability in
this document.
Note, in the output table, $x_1$ stands for an arbitrary name of the first
explanatory variable, that $\hat{\beta}_1$ is the corresponding estimated
coefficient, and that $\alpha$ is the estimated coefficient on the constant.
Also, $N$ means the actual number of observations used in the
regression, not just the letter $N$.
In the future we will add to goodness-of-fit statistics to the output.
%
\begin{table}[ht]
	\caption{Linear Regression Estimation Output Format}
	\protect\label{ta:lreg-est}
	\begin{center}
	\begin{tabular}{cccc}
		Variable & Estimate & St.\ Error & t-statistic \\ \hline
		$\mathit{Constant}$ & $\hat{\alpha}$ & $\sqrt{V(\hat{\alpha},\hat{\alpha})}$
			& $t(\hat{\alpha})$ \\
		$x_1$	& $\hat{\beta}_1$ & $\sqrt{V(\hat{\beta}_1,\hat{\beta}_1)}$
			& $t(\hat{\beta}_1)$ \\
		$x_2$	& $\hat{\beta}_2$ &	$\sqrt{V(\hat{\beta}_2,\hat{\beta}_2)}$
			& $t(\hat{\beta}_2)$ \\
		$x_3$	& $\hat{\beta}_2$ & $\sqrt{V(\hat{\beta}_2,\hat{\beta}_2)}$
			& $t(\hat{\beta}_2)$ \\ \hline
		\multicolumn{4}{l}{Number of observations: $N$}
	\end{tabular}
	\end{center}
\end{table}



%
%
\subsection{Multinomial Logit Estimation---Maximum Likelihood with 
Newton Optimization}

Logit model estimation can only proceed once the logit log-likelihood
function has been generated by the function generator. 
It incorporates data lookup and all
coefficient restrictions. It is then passed to a multi-variate
function optimizer, with the input optimization parameters, i.e.
tolerances, maximum number of iterations, and starting values for the
coefficients. The logit log-likelihood function is globally concave and
its analytical derivatives can be calculated or numerically estimated. 

We use Newton optimization (see Section~\ref{se:newton}) 
to locate the maximum of the logit log-likelihood function
and this yields the associated coefficient estimates for the vector of
unique estimable coefficients: $\hat{\vc{\beta}}$.

Pass to the Newton optimizer the:
\begin{enumerate}
	\item Generated logit log-likelihood function (which can supply its 
	value, its gradient, and its Hessian, all evaluated at input values);

	\item Starting values for $\vc{\beta}_\mathit{start}$ 
	(we use 0 as default if nothing is given by
	the user but that is handled by the estimation controller, which will
	pass in the array of all zero coefficients); 

	\item Maximum number of iterations; 
	
	\item Tolerances on the function, coefficient, and gradient values 
	(we use default values if nothing is given there); 
	
\end{enumerate}
%
The optimizer returns the estimated coefficient values, 
$\hat{\vc{\beta}}$.

We now need to calculate the estimated variance-covariance matrix of 
the estimates, $\vc{V}(\hat{\vc{\beta}})$.
The estimated variance-covariance
matrix of $\hat{\vc{\beta}}$ is:
%
\begin{equation}
	\vc{V}(\hat{\vc{\beta}}) = \vc{H}^{-1}(\hat{\vc{\beta}}),
\end{equation}
%
where $\vc{H}$ is the Hessian matrix of the logit log-likelihood function, 
$\vc{H}^{-1}$ represents the inverted Hessian, 
and it is evaluated at $\hat{\vc{\beta}}$. 
The $i,j$-th element of $\vc{V}(\hat{\vc{\beta}})$ is denoted by
$V(\hat{\beta}_i,\hat{\beta}_j)$. 

The (asymptotically correct) t-statistic is now calculated as
%
\begin{equation}
	t(\hat{\beta}_k) = 
		\frac{\hat{\beta}_k}{\sqrt{V(\hat{\beta}_k,\hat{\beta}_k)}}.
\end{equation}

The estimated coefficients must be output, and now it is key to
recognize the restricted coefficients since we must output the
appropriate coefficient on the actual separate explanatory variables.
To do this, we use the mapping between all possible coefficents and 
the unique estimable 
coefficients, the matrix $\vc{B}$ as defined in (\ref{eq:bck-matrix}) and
whose elements are denoted by $B(c,j)$. The output information
for our example is shown in Table~\ref{ta:mnl-est}. The horizontal lines
are for readability in this document.
%
Note that in the output table, $x_j$ stands for the 
arbitrary name of the $j$-th
explanatory variable, $B(c,j)$ is its coefficient estimate for
alternative $c$. $B(c,j)$ can of course be zero, it may have been
restricted to another real number, or it is an estimated coefficient
which is possibly shared with another variable or this variable in
another alternative. All of this is captured by the matrix $\vc{B}$ which is
generated along with the logit log-likelihood function. The codes $N_c$
stand for the actual number of decision makers that chose alternative
$c$, $N$ stands for the actual total number of decision makers
(observations). The log-likelihood values are the resulting values from
evaluating the logit log-likelihood function at the indicated values,
and $\rho^2$ is a goodness-of-fit statistic, calculated as shown.
%
\begin{table}[ht]
	\caption{Multinomial Logit Estimation Output Format}
	\protect\label{ta:mnl-est}
	\begin{center}
	\begin{tabular}{cccc}
		Variable & Estimate & St.\ Error & t-statistic \\ \hline
		\multicolumn{4}{l}{Name of Alternative 1} \\
		$\mathit{Constant}$ & $B(1,1)$ & $\sqrt{V(B(1,1),B(1,1))}$ & $t(B(1,1))$ \\
		$x_1$	& $B(1,2)$	& $\sqrt{V(B(1,2),B(1,2))}$	& $t(B(1,2))$ \\
		$x_2$	& $B(1,3)$	& $\sqrt{V(B(1,3),B(1,3))}$	& $t(B(1,3))$ \\
		$x_3$	& $B(1,4)$	& $\sqrt{V(B(1,4),B(1,4))}$	& $t(B(1,4))$ \\
		$\cdots$ & $\cdots$ & $\cdots$ 					& $\cdots$ \\
		\multicolumn{4}{l}{Name of Alternative $C$}\\
		$\mathit{Constant}$ & $B(C,1)$ & $\sqrt{V(B(C,1),B(C,1))}$ & $t(B(C,1))$ \\
		$x_1$	& $B(C,2)$	& $\sqrt{V(B(C,2),B(C,2))}$	& $t(B(C,2))$ \\
		$x_2$	& $B(C,3)$	& $\sqrt{V(B(C,3),B(C,3))}$	& $t(B(C,3))$ \\
		$x_3$	& $B(C,4)$	& $\sqrt{V(B(C,4),B(C,4))}$	& $t(B(C,4))$ \\ \hline
		\multicolumn{4}{l}{Number of decison makers choosing alternative 1: $N_1$} \\
		\multicolumn{4}{l}{\hss$\cdots$\hss} \\
		\multicolumn{4}{l}{Number of decison makers choosing alternative C: $N_C$} \\
		\multicolumn{4}{l}{Number of observations: $N$} \\
		\multicolumn{4}{l}{Log-Likelihood at zero: $L(\vc{0})$} \\
		\multicolumn{4}{l}{Log-Likelihood at starting: $L(\vc{\beta}_{\mathit{start}})$} \\
		\multicolumn{4}{l}{Log-Likelihood at convergence: $L(\hat{\vc{\beta}})$} \\
		\multicolumn{4}{l}{$\rho^2$: $1-L(\hat{\vc{\beta}})/L(\vc{0})$}
	\end{tabular}
	\end{center}
\end{table}
%


%
%
\subsection{Newton Optimization}
\label{se:newton}

Given a function, $L$ which can return its value $L(\vc{\beta})$, 
its gradient $\vc{\nabla} L(\vc{\beta})$, and
its Hessian $\vc{\nabla}^2 L(\vc{\beta})$, all evaluated at
$\vc{\beta}$; 
along with maximum number of iterations, step size, and tolerance limits
($\epsilon_f$, $\epsilon_c$, $\epsilon_g$),
the Newton optimization is relatively simple. Recall that $\vc{\beta}$ is a
vector of all unique coefficients, and let us in this algorithm use
$\vc{\beta}_i$ to represent the $i$-th estimate of the coefficient
vector, as opposed to the $i$-th element of the vector.

\begin{enumerate}\itemsep=0cm
\item \textbf{Input:} Function $L$, $\vc{\beta}_{\mathit{start}}$, step\_size,
maximum\_iterations, $\epsilon_f$, $\epsilon_b$, $\epsilon_g$
\item $\vc{\beta}_0 = \vc{\beta}_{\mathit{start}}$
\item $\sigma = $ step\_size
\item $i = 0$
\item tolerance\_exceeded = TRUE
\item \textbf{Do While} ($i <$ maximum\_iterations AND 
	tolerance\_exceeded)
\item $\vc{g} = \vc{\nabla} L(\vc{\beta}_i)$
\item $\vc{H} = \vc{\nabla}^2 L(\vc{\beta}_i)$
\item $\vc{P} = -\vc{H}^{-1}\vc{g}$
\item $\vc{\beta}_{i+1} = \vc{\beta}_i + \sigma \vc{P}$
\item tolerance\_exceeded = 
		($|L(\vc{\beta}_i) - L(\vc{\beta}_{i+1})| > \epsilon_f$) 
	OR ($|\vc{\beta}_i - \vc{\beta}_{i+1}| > \epsilon_b$)
	OR ($|\vc{\nabla} L(\vc{\beta}_i) - \vc{\nabla} L(\vc{\beta}_{i+1})|
			> \epsilon_g$)
\item $i = i + 1$
\item \textbf{End Do}
\item \textbf{Return:} $\vc{\beta}_i$
\end{enumerate}

Note that $\vc{H}^{-1}$ indicates that the Hessian matrix has been inverted. 
The main difficulty that can arise is during the inversion of the
Hessian matrix if it is singular, or if this matrix is not
negative-definite. A singular matrix cannot be inverted so exit
gracefully with a message indicating a singularity in the Hessian. A
non-negative-definite Hessian is contradictory to global concavity and
the algorithm cannot converge. Maximum number of iterations will be
reached, and an abnormal exit should be indicated.

All input tolerances must be
satisfied, i.e. no tolerance can be exceeded, 
if there are no input tolerances we must use default
values of $\epsilon = 10^{-5}$ for all checks.
If there is no input step size we must use $\sigma = 1$. The estimation
controller should handle these defaults and pass them to the optimizer
if needed.

Recall, $\epsilon_f =$ maximum absolute change in likelihood function across
iterations, $\epsilon_b =$ maximum absolute change in coefficients across
iterations, and $\epsilon_g =$ maximum absolute gradient.

It is not necessary to store all $i$ estimates, it is only necessary to
store the two latest estimates.


%
%
%
\begin{thebibliography}{99}

\bibitem{lawson:95}
Lawson, C. L., R. J. Hanson, (1995):
\emph{Solving Least Squares Problems.} 
Society of Industrial \& Applied Mathematics.
\href{http://www.netlib.org/lawson-hanson/all}
{The Fortran code is available on Netlib}.

\bibitem{press:92}
Press, W. H., S. A. Teukolsky, B. P. Flannery, W. T. Vetterling, (1992):
\emph{Numerical Recipes in C: The Art of Scientific Computing.}
The Press Syndicate of the University of Cambridge.

\end{thebibliography}

%
%
%
\appendix

%
%
%
\section{Matrix Computations}
\label{ap:matrix}

To perform the necessary matrix computations ourselves it is necessary to have a
Java class library for matrices that supports the following for matrices
and vectors:
%
\begin{itemize}
\item addition of matrices or vectors
\item multiplication of matrices and/or vectors
\item multiplication of matrices and/or vectors by a scalar
\item transpose for matrices and vectors
\item inverse for matrices
\end{itemize}
%
For the matrix calculations, we currently recommend using the
public-domain matrix package, 
\href{http://math.nist.gov/javanumerics/jama}{JAMA}.
%
We recommend using a currently available Java matrix package
rather than implement these methods ourselves, since implementing numerical
methods is complicated and does usually not follow the same algorithm
humans employ when calculating by hand. It is imperative that numerical
accuracy be maintained in the algorithm and we not loose accuracy
because of a naive implementation.

The \href{http://www.vni.com/products/jmsl}{JMSL 2.0 library} 
(commercial software) 
is a proprietary library available that performs both linear regression
and function optimization. 
The JMSL class, Matrix, has the necessary features (addition, multiplication,
transpose), the class LU supplies matrix inverse, the class LinearRegression  
implements a linear regression 
much better (numerically speaking) than the naive method of implementing the
formulas directly as shown in this document. JMSL takes care to protect numerical
accuracy. To quote:
\begin{quote}
 In order to compute a least-squares solution, 
 LinearRegression performs an orthogonal reduction of the matrix of 
 regressors to upper triangular form. Givens rotations are used to 
 reduce the matrix. This method has the advantage that the loss of 
 accuracy resulting from forming the crossproduct matrix used in 
 the normal equations is avoided, while not requiring the storage 
 of the full matrix of regressors. The method is described by 
 Lawson and Hanson \cite{lawson:95}.
\end{quote}
JMSL also has a class, MinUnconMultiVar, which supplies a quasi-Newton
optimization (BFGS), which is slightly different from the Newton optimization
shown in this document, but which can be used by us (some points in the
spec would have to be changed to match their interface and their
tolerance criteria).
They find a minimum so we would send the negative of our
logit log-likelihood to that class to be minimized, and that gives the
maximum likelihood estimate.

The producer of JMSL 2.0 is Visual Numerics Corp. and can be reached
at 1 (800) 364-8880, or \href{mailto:info@vni.com}{info@vni.com}.


%
%
%
\section{Sample Input Parameter XML File}
\label{ap:sample-xml}

Example of an input parameter XML file.
%
\begin{verbatim}
<Estimator_Parameters>
    <Project title="Eugene">
        <Model type="Linear_Regression">
            <estimation method="OLS">
            </estimation>
            <model-spec title="Land Price Model">
                <data location="file">
                    land-price-data.tab
                </data>
                <data-specification dependent_variable="ln_land_price">
                    residential_units,non_residential_sqft
                </data-spec>
                <model-structure>
                    land-price-model.txt
                </model-structure>
            </model-spec>
            <Outputs>
                Coefficient_XML,Documentation
            </Outputs>
        </Model>
        <Model type="Multinomial_Logit">
            <estimation method="ML" algorithm="Newton">
                <algorithm-parameters iterations="100" stepsize="1">
                </algorithm-parameters>
                <algorithm-tolerances function="0.00001" 
                    coefficients="0.00001"
                    gradient="0.00001">
                </algorithm-tolerances>
            </estimation>
            <model-spec title="Residential Location Choice">
                <data location="file">
                    residential-data.tab
                </data>
                <data-specification choice_indicator="choice_indicator"
                    alternative_id="alternative_id">
                    residential_units,non_residential_sqft
                </data-spec>
                <model-structure>
                    residential-model.txt
                </model-structure>
                <starting-values>
                    0,0
                </starting-values>
            </model-spec>
            <Outputs>
                Coefficient_XML,Documentation
            </Outputs>
        </Model>
        <Model type="Multinomial_Logit">
            <estimation method="ML" algorithm="Newton">
                <algorithm-parameters iterations="100" stepsize="1">
                </algorithm-parameters>
                <algorithm-tolerances function="0.00001" 
                    coefficients="0.00001"
                    gradient="0.00001">
                </algorithm-tolerances>
            </estimation>
            <model-spec title="Developer">
                <data location="file">
                    developer-data.tab
                </data>
                <data-specification choice_indicator="choice_indic"
                    alternative_id="alt_id_2">
                    cost,land_price,accessibility,density
                </data-spec>
                <model-structure>
                    developer-model.txt
                </model-structure>
                <starting-values>
                    0,0,0,0,0,0
                </starting-values>
            </model-spec>
            <Outputs>
                Coefficient_XML,Documentation
            </Outputs>
        </Model>
    </Project>
    <Project title="Utah">
        <!> Optional second project with one or more models </!>
    </Project>
</Estimator_Parameters>
\end{verbatim}



\begin{table}[htbp]
\begin{center}
\caption{Sample data file for linear regression:
\textbf{land-price-data.tab}.}
\begin{verbatim}
cell_id  ln_land_price  residential_units  non_residential_sqft
1        3.4            2                  50
...      ...            ...                ...
10000    4.3            26                 450
\end{verbatim}
\end{center}
\end{table}

\begin{table}[htbp]
\begin{center}
\caption{Sample model structure file for linear regression: 
\textbf{land-price-model.txt}.}
\begin{verbatim}
    ln_land_price = intercept_term
    + residential_units_coeff*residential_units
    + non_residential_sqft_coeff * non_residential_sqft
\end{verbatim}
\end{center}
\end{table}


\begin{table}[htbp]
\begin{center}
\caption{Sample data file for multionmial logit: 
\textbf{residential-data.tab}.}
\begin{verbatim}
decision_maker_id  alternative_id  choice_indicator access_to_pop
1                  location_1      0                345
1                  location_2      1                467
...                ...             ...              ...
5000               location_1      1                789
5000               location_2      0                123
\end{verbatim}
\end{center}
\end{table}

\begin{table}[htbp]
\begin{center}
\caption{Sample model structure file for multionmial logit: 
\textbf{residential-model.txt}.}
\begin{verbatim}
    U(location_1) = 0
    U(location_2) = location_2_constant 
            + access_coeff * access_to_pop
\end{verbatim}
\end{center}
\end{table}


\begin{table}[htbp]
\begin{center}
\caption{Sample data file for multionmial logit: 
\textbf{developer-data.tab}.}
\begin{verbatim}
dec_maker_id  alt_id_1  alt_id_2  choice_indic  cost   ...
1             1         -1        0             0      ...
1             1         1         1             34000  ...
1             1         2         0             24000  ...
...           ...       ...       ...           ...    ...
5000          1         -1        1             0      ...
5000          1         1         0             78000  ...
5000          1         2         0             129000 ...
\end{verbatim}
\end{center}
\end{table}

\begin{table}[ht]
\begin{center}
\caption{Sample model structure file for multionmial logit: 
\textbf{developer-model.txt}.}
\begin{verbatim}
    U(-1,1,2) = <0,house_constant,apt_constant>
        + <0,cost_coeff,cost_coeff>*cost
        + <0,price_house,price_apt> * land_price
        + <0,accessdens,6>*accessibility
        + <0,accessdens,accessdens> * density
\end{verbatim}
\end{center}
\end{table}

%
%
%
\clearpage
\section{Output Formats}
\label{ap:output}

\begin{description}
\item[Coefficient\_XML:] This example is not
available, since it should match the yet to be determined form that UrbanSim
will use to read coefficients.

\item[Documentation:] should be on the form shown in
Tables~\ref{ta:lreg-est}--\ref{ta:mnl-est}.
\end{description}


\end{document}



